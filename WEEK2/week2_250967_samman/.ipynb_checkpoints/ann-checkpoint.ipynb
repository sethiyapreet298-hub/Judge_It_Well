{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86010340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.6848\n",
      "Epoch [20/1000], Loss: 0.6689\n",
      "Epoch [30/1000], Loss: 0.6532\n",
      "Epoch [40/1000], Loss: 0.6362\n",
      "Epoch [50/1000], Loss: 0.6168\n",
      "Epoch [60/1000], Loss: 0.5944\n",
      "Epoch [70/1000], Loss: 0.5697\n",
      "Epoch [80/1000], Loss: 0.5440\n",
      "Epoch [90/1000], Loss: 0.5191\n",
      "Epoch [100/1000], Loss: 0.4973\n",
      "Epoch [110/1000], Loss: 0.4804\n",
      "Epoch [120/1000], Loss: 0.4682\n",
      "Epoch [130/1000], Loss: 0.4595\n",
      "Epoch [140/1000], Loss: 0.4527\n",
      "Epoch [150/1000], Loss: 0.4470\n",
      "Epoch [160/1000], Loss: 0.4422\n",
      "Epoch [170/1000], Loss: 0.4378\n",
      "Epoch [180/1000], Loss: 0.4337\n",
      "Epoch [190/1000], Loss: 0.4298\n",
      "Epoch [200/1000], Loss: 0.4258\n",
      "Epoch [210/1000], Loss: 0.4217\n",
      "Epoch [220/1000], Loss: 0.4176\n",
      "Epoch [230/1000], Loss: 0.4134\n",
      "Epoch [240/1000], Loss: 0.4092\n",
      "Epoch [250/1000], Loss: 0.4051\n",
      "Epoch [260/1000], Loss: 0.4009\n",
      "Epoch [270/1000], Loss: 0.3966\n",
      "Epoch [280/1000], Loss: 0.3920\n",
      "Epoch [290/1000], Loss: 0.3873\n",
      "Epoch [300/1000], Loss: 0.3827\n",
      "Epoch [310/1000], Loss: 0.3782\n",
      "Epoch [320/1000], Loss: 0.3740\n",
      "Epoch [330/1000], Loss: 0.3701\n",
      "Epoch [340/1000], Loss: 0.3665\n",
      "Epoch [350/1000], Loss: 0.3632\n",
      "Epoch [360/1000], Loss: 0.3603\n",
      "Epoch [370/1000], Loss: 0.3576\n",
      "Epoch [380/1000], Loss: 0.3552\n",
      "Epoch [390/1000], Loss: 0.3531\n",
      "Epoch [400/1000], Loss: 0.3512\n",
      "Epoch [410/1000], Loss: 0.3495\n",
      "Epoch [420/1000], Loss: 0.3480\n",
      "Epoch [430/1000], Loss: 0.3467\n",
      "Epoch [440/1000], Loss: 0.3454\n",
      "Epoch [450/1000], Loss: 0.3443\n",
      "Epoch [460/1000], Loss: 0.3433\n",
      "Epoch [470/1000], Loss: 0.3423\n",
      "Epoch [480/1000], Loss: 0.3414\n",
      "Epoch [490/1000], Loss: 0.3405\n",
      "Epoch [500/1000], Loss: 0.3396\n",
      "Epoch [510/1000], Loss: 0.3388\n",
      "Epoch [520/1000], Loss: 0.3381\n",
      "Epoch [530/1000], Loss: 0.3374\n",
      "Epoch [540/1000], Loss: 0.3367\n",
      "Epoch [550/1000], Loss: 0.3360\n",
      "Epoch [560/1000], Loss: 0.3354\n",
      "Epoch [570/1000], Loss: 0.3348\n",
      "Epoch [580/1000], Loss: 0.3342\n",
      "Epoch [590/1000], Loss: 0.3337\n",
      "Epoch [600/1000], Loss: 0.3332\n",
      "Epoch [610/1000], Loss: 0.3327\n",
      "Epoch [620/1000], Loss: 0.3322\n",
      "Epoch [630/1000], Loss: 0.3317\n",
      "Epoch [640/1000], Loss: 0.3312\n",
      "Epoch [650/1000], Loss: 0.3307\n",
      "Epoch [660/1000], Loss: 0.3303\n",
      "Epoch [670/1000], Loss: 0.3298\n",
      "Epoch [680/1000], Loss: 0.3294\n",
      "Epoch [690/1000], Loss: 0.3291\n",
      "Epoch [700/1000], Loss: 0.3287\n",
      "Epoch [710/1000], Loss: 0.3284\n",
      "Epoch [720/1000], Loss: 0.3280\n",
      "Epoch [730/1000], Loss: 0.3277\n",
      "Epoch [740/1000], Loss: 0.3275\n",
      "Epoch [750/1000], Loss: 0.3272\n",
      "Epoch [760/1000], Loss: 0.3270\n",
      "Epoch [770/1000], Loss: 0.3267\n",
      "Epoch [780/1000], Loss: 0.3264\n",
      "Epoch [790/1000], Loss: 0.3262\n",
      "Epoch [800/1000], Loss: 0.3260\n",
      "Epoch [810/1000], Loss: 0.3258\n",
      "Epoch [820/1000], Loss: 0.3256\n",
      "Epoch [830/1000], Loss: 0.3254\n",
      "Epoch [840/1000], Loss: 0.3253\n",
      "Epoch [850/1000], Loss: 0.3251\n",
      "Epoch [860/1000], Loss: 0.3250\n",
      "Epoch [870/1000], Loss: 0.3248\n",
      "Epoch [880/1000], Loss: 0.3246\n",
      "Epoch [890/1000], Loss: 0.3244\n",
      "Epoch [900/1000], Loss: 0.3242\n",
      "Epoch [910/1000], Loss: 0.3240\n",
      "Epoch [920/1000], Loss: 0.3238\n",
      "Epoch [930/1000], Loss: 0.3236\n",
      "Epoch [940/1000], Loss: 0.3235\n",
      "Epoch [950/1000], Loss: 0.3233\n",
      "Epoch [960/1000], Loss: 0.3231\n",
      "Epoch [970/1000], Loss: 0.3229\n",
      "Epoch [980/1000], Loss: 0.3227\n",
      "Epoch [990/1000], Loss: 0.3225\n",
      "Epoch [1000/1000], Loss: 0.3223\n",
      "Accuracy: 0.8585\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Churn_Modelling.csv')  # Adjust the path as necessary\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Handle Categorical Data\n",
    "df = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True)\n",
    "X = df.drop('Exited', axis=1).values\n",
    "y = df['Exited'].values\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChurnPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 16) # 11 features, 16 neurons in first hidden layer\n",
    "        self.fc2 = nn.Linear(16, 16) # 16 neurons in second hidden layer\n",
    "        self.output = nn.Linear(16, 1) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "model = ChurnPredictor()\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "    labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(torch.tensor(y_test).unsqueeze(1)).sum() / float(y_test.shape[0])\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
